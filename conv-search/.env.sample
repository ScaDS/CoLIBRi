### Copy this file and rename to .env
### Put actual settings and secrets

# Retrieval method to use. Can be either
# "LOCAL": local embedding model, downloaded and served via HuggingFace embeddings
# "REMOTE": embedding model hosted at a remote LLM endpoint and declared in REMOTE_EMBED_MODEL
RETRIEVAL_METHOD=REMOTE

# Huggingface identifier for local embedding model if RETRIEVAL_METHOD is set to LOCAL
LOCAL_EMBED_MODEL=BAAI/bge-m3

# Type of LLM to use. Can be either
# "OLLAMA": local LLM served via Ollama
# "REMOTE": LLM hosted at a remote LLM API
LLM_TYPE=REMOTE

# If OLLAMA for LLM, specify Ollama host URL and model name here
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:14b

# Parameters for remote LLM API
REMOTE_URL=remote_api_url
REMOTE_MODEL=vllm-llama-4-scout-17b-16e-instruct
REMOTE_EMBED_MODEL=vllm-baai-bge-m3
REMOTE_API_KEY=remote_api_key
